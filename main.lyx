#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass acmart
\begin_preamble
\usepackage{pgfplots}
\usepackage{subcaption}
\usepackage{adjustbox}
\usepackage{url}
%\usepackage{minted}


\usepgfplotslibrary{groupplots,dateplot}
\usetikzlibrary{
    patterns,
    chains,
    backgrounds,
    calc,
    shadings,
    shapes.arrows,
    arrows,
    shapes.symbols,
    shadows,
    positioning,
    decorations.markings,
    backgrounds,
    arrows.meta,
    external
}
\usepackage{array}
\usepackage{algorithmicx,algpseudocode}
% declaration of the new block
\algblock{ParFor}{EndParFor}
% customising the new block
\algnewcommand\algorithmicparfor{\textbf{parfor}}
\algnewcommand\algorithmicpardo{\textbf{do}}
\algnewcommand\algorithmicendparfor{\textbf{end}}
\algrenewtext{ParFor}[1]{\algorithmicparfor\ #1\ \algorithmicpardo}
\algrenewtext{EndParFor}{\algorithmicendparfor}
\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\pgfplotsset{compat=newest}

\newcommand{\code}[1]{\texttt{#1}}

\newif\iffinal

\iffinal
  \newcommand{\maxx}[1]{}
  \newcommand{\ryan}[1]{}
  \newcommand{\todo}[1]{}
\else
  \newcommand{\maxx}[1]{{\textcolor{red}{ Max: #1 }}}
  \newcommand{\ryan}[1]{{\textcolor{magenta}{ Ryan: #1 }}}
  \newcommand{\todo}[1]{{\textcolor{blue}{ TODO: #1 }}}
\fi
\end_preamble
\options sigconf,nonacm
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding utf8
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 1
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 0
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 2
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Ultrafast focus detection using multi-scale histologic features
\end_layout

\begin_layout Author
Maksim Levental
\end_layout

\begin_layout Affiliation
\begin_inset Flex Institution
status collapsed

\begin_layout Plain Layout
University of Chicago
\end_layout

\end_inset


\end_layout

\begin_layout Author
Ryan Chard
\end_layout

\begin_layout Affiliation
\begin_inset Flex Institution
status collapsed

\begin_layout Plain Layout
Argonne National Laboratory
\end_layout

\end_inset


\end_layout

\begin_layout Author
Gregg A.
 Wildenberg
\end_layout

\begin_layout Affiliation
\begin_inset Flex Institution
status collapsed

\begin_layout Plain Layout
University of Chicago
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
We present a fast out-of-focus detection algorithm for electron microscopy
 images collected serially.
 Such images are collected for the purposes of post-processing tasks such
 as montaging, alignment, and image segmentation.
 Such an algorithm is necessitated by recent increases in collection rates
 owing to advances in microscopy technology.
 Our technique, 
\shape italic
Multi-scale Histologic Feature Detection
\shape default
, adapts classical computer vision techniques and is based on detecting
 various fine-grained histologic features.
 We further exploit the inherent parallelism in the technique by employing
 GPGPU primitives in order to accelerate characterization.
 Tests are performed that demonstrate near-real-time detection of out-of-focus
 conditions.
 <We also deploy to funcX something something>.
 We discuss extensions that enable scaling out to support multi-beam microscopes
 and integration with existing focus systems for purposes of implementing
 auto-focus.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "sec:intro"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
Advancements in the automation of serial scanning electron microscopy (SEM)
 impose a regime where thousands, if not tens of thousands, of images can
 now be automatically collected by researchers.
 This puts greater demand on conventional auto-focus algorithms for ensuring
 each image is in focus, as an alternative to the user manually evaluating
 each image by eye.
 Without such algorithms, critical bottlenecks are created where the user
 is forced to reacquire individual, deficient (out-of-focus), images and
 manually reinsert them into the sequence of thousands of other images already
 acquired.
 This is an onerous task which requires taking into account alignment and
 boundary overlap.
 Furthermore, failure to quickly identify and reacquire deficient images
 negatively impacts the accuracy of downstream, post-processing; for example
 2D montaging, 3D alignment, or automatic segmentation pipelines.
 While many microscopes have builtin auto-focus algorithms, these often
 fail to achieve acceptable accuracy due to intrinsic mediating factors
 (e.g.
 stage drift) and extrinsic mediating factors (e.g.
 sample artifacts, non-uniformity in the sample).
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A fundamental goal of neuroscience is to map the anatomical relationships
 of the brain.
 Currently this is challenging because electron microscopy, an imaging method
 traditionally limited to small images, is the only imaging modality with
 sufficient resolution to directly visualize the connections, or synapses,
 between neurons.
 Recently, automated serial electron microscopy, broadly called 
\shape italic
connectomics
\shape default
, has been developed.
 This technique is characterized by thousands, if not tens of thousands,
 of individual images being automatically acquired in series and then registered
 to produce a volumetric dataset.
 Such datasets allow neuroscientists to follow the tortuous path neurons
 take through the brain to connect with each other (hence the name connectomics).
 However, many of the steps that comprise the collection of such datasets
 for connectomics require manual inspection causing significant slowdowns
 in the rate at which datasets can be acquired.
 Such bottlenecks significantly impact the size of the datasets that can
 be reasonably acquired and studied.
 Furthermore, advances in electron microscopes have increased the rate that
 datasets can be acquired (e.g.
 ~10 Tbs/24hr 
\begin_inset CommandInset citation
LatexCommand citet
key "zeiss:multisem550"
literal "false"

\end_inset

) .
 This further underscores the need for automation (in order that end-to-end
 high throughput is achieved).
 
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
Thus, without high fidelity automation of the imaging pipeline, the field
 of connectomics will fail to advance and realize its full potential.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Auto-focus technology is a critical component of many imaging systems; from
 consumer cameras (for purposes of convenience) to industrial inspection
 tools to scientific instrumentation 
\begin_inset CommandInset citation
LatexCommand citep
key "1545017"
literal "false"

\end_inset

.
 Such technology is typically either 
\shape italic
active
\shape default
 or 
\shape italic
passive
\shape default
; active methods exploit some auxiliary device or mechanism to measure the
 distance of the optics from the scene, while passive methods analyze the
 definition or sharpness of an image by virtue of a proxy measure called
 a 
\shape italic
criterion function
\shape default
.
 Many electron microscopes incorporate auto-focus techniques that attempt
 to focus the microscope before image acquisition.
 Despite such functionality, out-of-focus (OOF) images still occur at high
 rates (between 1% and 10%), depending on the quality of the tissue sections
 being imaged.
 Such error rates prevent effective automation since a prerequisite of the
 downstream operations are that the images collected all have high degree-of-foc
us (DOF).
 Without properly focused images, all downstream computational steps (e.g.
 2D tile montaging, 3D alignment, automatic segmentation) will fail.
\end_layout

\begin_layout Standard
Thus, we seek to further the aims of automation by ensuring that images
 acquired by the electron microscope have high DOF.
 While seemingly a small step in the process, focus detection is nevertheless
 an extremely critical step.
 Consequently, because imaging sections requires loading and unloading sets
 of ~100-200 sections at a time, failure to manually detect an out of focus
 image in real time causes significant delays.
 The affected sample sets need to be reloaded, desired field of view must
 be reconfigured, and reaquired images need to be reinserted into the image
 stack.
 All such remediation steps are time and labor intensive.
\end_layout

\begin_layout Standard
Our proposed technique, 
\shape italic
Multi-scale Histologic Feature Detection
\shape default
 (MHFD), involves a second pass over the collected image, after it has been
 acquired, using a computer vision system to detect a failure to successfully
 achieve high DOF.
 We use feature detection 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindeberg2004FeatureDW"
literal "false"

\end_inset

 as a criterion function, reasoning that the quantity of features detected
 is positively correlated with DOF.
 To this end, we develop a feature detector based on scale-space representations
 of images (see section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Backround"

\end_inset

) but optimized for latency (rather than for accuracy).
 Our solution achieves low latency detection of the OOF condition with high
 correlation (see section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Evaluation"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 
\end_layout

\begin_layout Standard
Note that we explicitly aim to augment existing microscopy equipment without
 the need for costly and complex retrofitting.
 This precludes mere improvements to auto-focus systems as they are, in
 essence, proprietary black boxes from the perspective of the end user of
 a commerical electron microscope.
 
\end_layout

\begin_layout Standard
This rest of this article is organized as follows: section
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Backround"

\end_inset

 quickly reviews backround on scale-space feature detectors, section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:implementation"

\end_inset

 describes our focus detection method in the abstract and particular optimizatio
ns made in order to achieve near-real-time performance, section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Evaluation"
plural "false"
caps "false"
noprefix "false"

\end_inset

 reports results of evaluating our method on sequences of images collected
 at varying focus depths, section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Discussion"

\end_inset

 discuss those results, and section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:related"
plural "false"
caps "false"
noprefix "false"

\end_inset

 discusses related work and how our work is distinct therefrom.
\end_layout

\begin_layout Section
Scale-space representations
\begin_inset CommandInset label
LatexCommand label
name "sec:Backround"

\end_inset


\end_layout

\begin_layout Standard
We base our multi-scale histologic feature detection technique on classical
 scale-space representations of signals and images.
 We give a brief overview (see 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindeberg2004FeatureDW"
literal "false"

\end_inset

 for a more comprehensive review).
 
\end_layout

\begin_layout Standard
The fundamental principle of scale-space feature detection is that natural
 images possess structureful features at multiple scales and that features
 at a particular scale isolated from features at other scales.
 Thus any image 
\begin_inset Formula $I\left(x,y\right)$
\end_inset

 can transformed into a scale-space representation 
\begin_inset Formula $L\left(x,y,t\right)$
\end_inset

, where 
\begin_inset Formula $L\left(x',y',t'\right)$
\end_inset

 represents the pixel intensity
\shape italic

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Hence, scale-space since we consider the image along dimensions of scale
 and space.
\end_layout

\end_inset


\shape default
 at pixel coordinates 
\begin_inset Formula $\left(x',y'\right)$
\end_inset

 and 
\shape italic
scale 
\begin_inset Formula $t'$
\end_inset

.

\shape default
 How to produce the representation of the image at each scale is discussed
 in the forth coming.
 More importantly, such a representation lends itself readily to scale sensitive
 feature detection owing to the fact that features at a particular scale
 are decoupled from features at other scales, thereby eliminating confounding
 detections.
 Examples of structureful features that can be detected and characterized
 using scale-space representations include edges, corners, ridges, and so
 called blobs (roughly circular regions of uniform intensity).
\end_layout

\begin_layout Standard
A scale-space representation at a particular scale is constructed by convolution
 of the image with a filter that satisfies the constraints of non-enhancement
 of local extrema, scale invariance and rotational invariance (along with
 some others 
\begin_inset CommandInset citation
LatexCommand citep
key "duits2004axioms"
literal "false"

\end_inset

).
 One such filter 
\begin_inset CommandInset citation
LatexCommand citep
key "koenderink1984structure"
literal "false"

\end_inset

 is the symmetric, mean zero, two dimensional, Gaussian filter 
\begin_inset Formula 
\[
G\left(x,y,\sigma\right)\coloneqq\frac{1}{2\pi\sigma^{2}}e^{-\frac{x^{2}+y^{2}}{2\sigma^{2}}}
\]

\end_inset

Thus, define the scale-space representation 
\begin_inset Formula $L(x,y,t)$
\end_inset

 of an image 
\begin_inset Formula $I(x,y)$
\end_inset

 to be the convolution of that image with a mean zero Gaussian filter: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L\left(x,y,t\right)\coloneqq G\left(x,y,t\right)*I\left(x,y\right)
\]

\end_inset

where 
\begin_inset Formula $t$
\end_inset

 determines the scale.
 
\begin_inset Formula $L(x,y,t)$
\end_inset

 has the interpretation that image structures of scale smaller than 
\begin_inset Formula $\sqrt{t^{2}}=t$
\end_inset

 have been removed due to blurring.
 This is due to the fact that the variance of the Gaussian filter is 
\begin_inset Formula $t^{2}$
\end_inset

 and features of this scale are therefore 
\begin_inset Quotes eld
\end_inset

beneath the noise floor
\begin_inset Quotes erd
\end_inset

 of the filter or, in effect, suppressed by filtering procedure.
 A corollary is that features with approximate length scale 
\begin_inset Formula $t$
\end_inset

 will have maximal response upon being filtered by 
\begin_inset Formula $G(x,y,t)$
\end_inset

.
 That is to say, for a 
\begin_inset Formula $t$
\end_inset

 scale feature at pixel coordinates 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 and for scales 
\begin_inset Formula $t'<t<t''$
\end_inset

 we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L\left(x,y,t'\right)<L\left(x,y,t\right)<L\left(x,y,t''\right)
\]

\end_inset

This is due to the fact that for scales 
\begin_inset Formula $t'<t$
\end_inset

, small scale features will dominate the response and for 
\begin_inset Formula $t<t''$
\end_inset

, as already mentioned, the feature will have been suppressed.
 
\end_layout

\begin_layout Standard
Note that the aforementioned presumes having identified the pixel coordinates
 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 as the locus of the feature.
 Thus, in order to detect features across scales and space, maximal responses
 in spatial dimensions 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 need to also be characterized.
 For such characterization one generally employs standard calculus in order
 to identify critical points of second order derivatives.
 Hence, we can construct scale-sensitive feature detectors by considering
 critical points of linear and non-linear combinations of spatial derivatives
 
\begin_inset Formula $\partial_{x},\partial_{y}$
\end_inset

 and derivatives in scale 
\begin_inset Formula $\partial_{t}$
\end_inset

.
 For example the scale derivative of the Laplacian
\begin_inset Formula 
\begin{equation}
\partial_{t}\nabla^{2}L\coloneqq\partial_{t}\left(\partial_{x}^{2}+\partial_{y}^{2}\right)L\label{eqn:blobdetector}
\end{equation}

\end_inset

effectively detects regions of uniform pixel intensity (i.e.
 blobs).
\end_layout

\begin_layout Section
Multi-scale Histologic Feature Detection
\begin_inset CommandInset label
LatexCommand label
name "sec:implementation"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{subfigure}[b]
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

0.5
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textwidth
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset Graphics
	filename in_focus.png
	lyxscale 50
	width 100line%

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Histologic features of an in-focus section.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subfig:infocus"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{subfigure}
\end_layout

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset VSpace medskip
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{subfigure}[b]
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

0.5
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textwidth
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset Graphics
	filename out_of_focus.png
	lyxscale 50
	width 100line%

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Histologic features of an out-of-focus section.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subfig:outoffocus"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{subfigure}
\end_layout

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of sections with histologic feature recognition as a function
 of focal depth.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:histfeatsimages"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We propose to use histologic feature detection at multiple scales as a criterion
 function, reasoning that the absolute quantity of features detected at
 multiple scales is positively correlated with DOF (see figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:histfeatsimages"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 For our particular use-case this is tantamount to detecting histologic
 structures ranging from cell walls to whole organelles.
 The key insight is that the ability to resolve structure across the range
 of feature scales is highly correlated with a high-definition image.
 To this end, we develop a feature detector based on eqn.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eqn:blobdetector"
plural "false"
caps "false"
noprefix "false"

\end_inset

 but optimized for latency (rather than for accuracy).
 
\end_layout

\begin_layout Standard
Firstly, in order to verify our hypothesis that detecting features across
 a range of scales is correlated with DOF, we compare the number of histologic
 features detected as a function of absolute deviation from in-focus (
\begin_inset Formula $\lvert f-f'\rvert$
\end_inset

 where 
\begin_inset Formula $f'$
\end_inset

 is the correct focal depth) for a series of sections with known focal depth
 (see figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subfig:degreeoofcurve"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 We observe a very strong log-linear relationship (see figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subfig:degreeooffit"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Fitting a log-linear relationship produces a line with 
\begin_inset Formula $r=-0.9754$
\end_inset

, confirming our hypothesis that quantity of histologic features detected
 is a good proxy measure for DOF.
 Note that the log-linear relationship corresponds to a roughly quadratic
 decrease in the number of histologic features detected.
 This is to be expected since, intuitively, a twice improved DOF of a two
 dimensional image yields improved detection along both spatial dimensions
 and thus a four times increased quantity of histologic features detected.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{subfigure}[b]
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

0.5
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textwidth
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand input
preview true
filename "blob_count_curve.tex"

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Number of histologic features as a function of absolute deviation from focused
 (
\begin_inset Formula $\lvert f-f'\rvert$
\end_inset

 where 
\begin_inset Formula $f'$
\end_inset

 is the correct focal depth).
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subfig:degreeoofcurve"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{subfigure}
\end_layout

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset VSpace medskip
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{subfigure}[b]
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

0.5
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textwidth
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand input
preview true
filename "blob_count_fit.tex"

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Log plot and line fit with 
\begin_inset Formula $r=-0.9754$
\end_inset

.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subfig:degreeooffit"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{subfigure}
\end_layout

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of histologic feature recognition as a function of focal depth.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:histfeats"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We now discuss the design and implementation
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/makslevental/cuda_blob/"
literal "false"

\end_inset


\end_layout

\end_inset

 of our multi-scale histologic feature detector, with particular attention
 paid to optimizations in consideration of inference latency.
 Eqn.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eqn:blobdetector"
plural "false"
caps "false"
noprefix "false"

\end_inset

 permits a discretization
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
By virtue of 
\begin_inset Formula $G$
\end_inset

 being the Green's function of the heat equation 
\begin_inset Formula $t\nabla^{2}G=\partial_{t}G$
\end_inset

.
\end_layout

\end_inset

 called 
\shape italic
Difference of Gaussians
\shape default
 (DoG) (see
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "marr1980theory"
literal "false"

\end_inset

) 
\begin_inset Formula 
\[
t^{2}\nabla^{2}L\approx t\times\left(L\left(x,y,t+\delta t\right)-L\left(x,y,t\right)\right)
\]

\end_inset

Therefore, define 
\end_layout

\begin_layout Itemize
\begin_inset Formula $n$
\end_inset

, which determines the granularity of the scales detected 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\min_{t}$
\end_inset

, the minimum scale detected 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\max_{t}$
\end_inset

, the maximum scale detected 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\delta t\coloneqq\left(\max_{t}-\min_{t}\right)/n$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $t_{i}\coloneqq\min_{t}+\left(i-1\right)\times\delta t$
\end_inset

, the discrete scales detected 
\end_layout

\begin_layout Standard
and finally the discretized DoG 
\begin_inset Formula 
\begin{equation}
\operatorname{DoG}\left(x,y,i\right)\coloneqq t_{i}\times\left(L\left(x,y,t_{i+1}\right)-L\left(x,y,t_{i}\right)\right)\label{eqn:dog}
\end{equation}

\end_inset

This produces a sequence 
\begin_inset Formula $\left\{ \operatorname{DoG}\left(x,y,i\right)\mid i=1,\dots,n\right\} $
\end_inset

 of filtered and scaled images (called a Gaussian pyramid 
\begin_inset CommandInset citation
LatexCommand citep
key "derpanis2005gaussian"
literal "false"

\end_inset

).
 Note that there are alternative convetions for how each difference in the
 definition of 
\begin_inset Formula $\operatorname{DoG}\left(x,y,i\right)$
\end_inset

 should be scaled (including partitioning into so called 
\shape italic
octaves
\shape default
 
\begin_inset CommandInset citation
LatexCommand citep
key "1095851"
literal "false"

\end_inset

) but we empirically determine that linear scaling is sufficient for our
 needs.
\end_layout

\begin_layout Standard
Computing maxima of 
\begin_inset Formula $\operatorname{DoG}\left(x,y,i\right)$
\end_inset

 in the scale dimension (equivalently critical points of eqn.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eqn:blobdetector"
plural "false"
caps "false"
noprefix "false"

\end_inset

) necessarily entails computing local
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In a small pixel neighborhood in both space and scale dimensions.
\end_layout

\end_inset

 maxima at every scale.
 We make the heuristic assumption that, in each pixel neighborhood that
 corresponds to a feature, there is a single unique and maximal response
 at some scale 
\begin_inset Formula $t$
\end_inset

.
 This response corresponds to the scale at which the variance of the Gaussian
 filter 
\begin_inset Formula $G$
\end_inset

 most closely corresponds to the scale of the feature (see section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sec:Backround"

\end_inset

).
 We therefore search for local maxima in spatial dimensions 
\begin_inset Formula $x,y$
\end_inset

 but global maxima in the scale dimension 
\begin_inset Formula 
\begin{equation}
\left\{ \left(\hat{x}_{j},\hat{y}_{j},\hat{i}_{j}\right)\right\} \coloneqq\operatorname*{argmaxlocal}_{x,y}\operatorname*{argmax}_{i}\operatorname{DoG}\left(x,y,i\right)\label{eqn:argmax}
\end{equation}

\end_inset

where the subscript 
\begin_inset Formula $j$
\end_inset

 indexes over the features detected.
 Once all such maxima are identified it suffices to compute and report the
 cardinality of 
\begin_inset Formula $\left\{ \left(\hat{x}_{j},\hat{y}_{j},\hat{i}_{j}\right)\right\} $
\end_inset

 as criterion function value.
\end_layout

\begin_layout Standard
We now discuss practical (i.e.
 implementation) optimizations.
 It is readily apparent that our histologic feature detector is parallelizable;
 for each scale 
\begin_inset Formula $t_{i}$
\end_inset

 we can compute 
\begin_inset Formula $L\left(x,y,t_{i}\right)$
\end_inset

 independently of all other 
\begin_inset Formula $L\left(x,y,t_{j}\right)$
\end_inset

 (for 
\begin_inset Formula $j\neq i$
\end_inset

).
 A further parallelization is possible for the 
\begin_inset Formula $\operatorname*{argmax}$
\end_inset

 operation, since the maxima are computed independently across distinct
 neighborhoods of pixels.
 In order to maximally exploit this we first perform the inner 
\begin_inset Formula $\operatorname*{argmax}$
\end_inset

 in eqn.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eqn:argmax"
plural "false"
caps "false"
noprefix "false"

\end_inset

 on block of columns of 
\begin_inset Formula $\left\{ \operatorname{DoG}\left(x,y,i\right)\right\} $
\end_inset

 in parallel, thereby effectively reducing the Gaussian pyramid to a single
 image.
 Note that when GPU memory is sufficient we can compute the 
\begin_inset Formula $\operatorname*{argmax}$
\end_inset

 across all columns simulataneously (and other wise within a constant number
 of steps).
 We then perform the outer 
\begin_inset Formula $\operatorname*{argmaxlocal}_{x,y}$
\end_inset

 on disjoint pixel neighborhoods of the flattened image in parallel as well.
 
\end_layout

\begin_layout Standard
Note that the implementation of the inner 
\begin_inset Formula $\operatorname*{argmax}$
\end_inset

 is 
\begin_inset Quotes eld
\end_inset

free
\begin_inset Quotes erd
\end_inset

, since the 
\begin_inset Formula $\operatorname*{argmax}$
\end_inset

 primitive is implemented in exactly this way in most GPGPU libraries 
\begin_inset CommandInset citation
LatexCommand citep
key "CUB"
literal "false"

\end_inset

 and thus our substitution of 
\begin_inset Formula $\operatorname*{argmax}_{i}$
\end_inset

 for 
\begin_inset Formula $\operatorname*{argmaxlocal}_{i}$
\end_inset

 yields a small but not insignificant latency decrease.
 The outer 
\begin_inset Formula $\operatorname*{argmaxlocal}$
\end_inset

 is implemented using a comparison against 
\begin_inset Formula $\operatorname{MaxPool2D}(n,n)$
\end_inset

 (with 
\begin_inset Formula $n=3$
\end_inset

) (see 
\begin_inset CommandInset citation
LatexCommand citep
key "9307788"
literal "false"

\end_inset

 for details on this technique).
 Employing 
\begin_inset Formula $\operatorname{MaxPool2D}$
\end_inset

 in this way has the added benefit of effectively performing non-maximum
 suppression 
\begin_inset CommandInset citation
LatexCommand citep
key "1699659"
literal "false"

\end_inset

, since it effectively rejects spurrious candidate maxima within a 
\begin_inset Formula $3\times3$
\end_inset

 neighborhood of a true maximum.
\end_layout

\begin_layout Standard
Typically one would compute 
\begin_inset Formula $L(x,y,t_{i})$
\end_inset

 in the conventional way (by linearly convolving 
\begin_inset Formula $G$
\end_inset

 and 
\begin_inset Formula $I$
\end_inset

) but prior work has shown 
\begin_inset CommandInset citation
LatexCommand citep
key "9307788"
literal "false"

\end_inset

 that performing the convolution in the Fourier domain is much more efficient;
 namely 
\begin_inset Formula 
\[
L\left(x,y,t_{i}\right)=\mathcal{F}^{-1}\big\{\mathcal{F}\left\{ G\left(x,y,t_{i}\right)\right\} \cdot\mathcal{F}\left\{ I\left(x,y\right)\right\} \big\}
\]

\end_inset

where 
\begin_inset Formula $\mathcal{F}\left\{ \cdot\right\} ,\mathcal{F}^{-1}\left\{ \cdot\right\} $
\end_inset

 are the Fourier transform and inverse Fourier transform, respectively.
 This approach has the additional advantage that we can make use of highly
 optimized Fast Fourier Transform (FFT) routines made available by GPGPU
 libraries.
\end_layout

\begin_layout Standard
One remaining detail is histogram stretching of the images.
 Due to the dynamic range (i.e.
 variable bit depth) of the microscope we need to normalize the histogram
 of pixel values; we do this by saturating 
\begin_inset Formula $.175\%$
\end_inset

 of the darkest pixels, saturating 
\begin_inset Formula $.175\%$
\end_inset

 of the lightest pixels, and mapping the entire range to 
\begin_inset Formula $[0,1]$
\end_inset

.
 We find this gives us consistently robust results with respect to noise
 and anomalous features.
 This histogram normalization is also parallelized using GPU primitives.
\end_layout

\begin_layout Standard
In summary our technique is presented in alg.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "alg:Multi-scale-Histologic-Feature"

\end_inset

.
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Multi-scale Histologic Feature Detection
\begin_inset CommandInset label
LatexCommand label
name "alg:Multi-scale-Histologic-Feature"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\begin_layout Plain Layout


\backslash
Require{$I
\backslash
left(x,y
\backslash
right), n, 
\backslash
min_{t}, 
\backslash
max_{t}, M$}
\end_layout

\begin_layout Plain Layout


\backslash
State $I'
\backslash
left(x,y
\backslash
right) 
\backslash
coloneqq 
\backslash
texttt{HistorgramStretch}(I
\backslash
left(x,y
\backslash
right))$
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
texttt{Broadcast}$
\backslash
left(I'
\backslash
left(x,y
\backslash
right), M
\backslash
right)$
\end_layout

\begin_layout Plain Layout


\backslash
ParFor{$m 
\backslash
coloneqq 1,
\backslash
dots, M$}
\end_layout

\begin_layout Plain Layout

  
\backslash
ParFor{$i
\backslash
in I_{m}$}
\end_layout

\begin_layout Plain Layout

    
\backslash
State $L
\backslash
left(x,y,t_{i}
\backslash
right) 
\backslash
coloneqq 
\backslash
mathcal{F}^{-1}
\backslash
big
\backslash
{
\backslash
mathcal{F}
\backslash
left
\backslash
{ G
\backslash
left(x,y,t_{i}
\backslash
right)
\backslash
right
\backslash
} 
\backslash
cdot
\backslash
mathcal{F}
\backslash
left
\backslash
{ I'
\backslash
left(x,y
\backslash
right)
\backslash
right
\backslash
} 
\backslash
big
\backslash
}$
\end_layout

\begin_layout Plain Layout

  
\backslash
EndParFor
\end_layout

\begin_layout Plain Layout


\backslash
EndParFor
\end_layout

\begin_layout Plain Layout


\backslash
State 
\backslash
texttt{Gather}$
\backslash
left(L
\backslash
left(x,y,t_{i}
\backslash
right), M
\backslash
right)$
\end_layout

\begin_layout Plain Layout


\backslash
ParFor{$i 
\backslash
coloneqq 1,
\backslash
dots, n+1$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $
\backslash
operatorname{DoG}
\backslash
left(x,y,i
\backslash
right)
\backslash
coloneqq t_{i}
\backslash
times
\backslash
left(L
\backslash
left(x,y,t_{i+1}
\backslash
right)-L
\backslash
left(x,y,t_{i}
\backslash
right)
\backslash
right)$
\end_layout

\begin_layout Plain Layout


\backslash
EndParFor
\end_layout

\begin_layout Plain Layout


\backslash
State $
\backslash
left
\backslash
{ 
\backslash
left(
\backslash
hat{x}_{j},
\backslash
hat{y}_{j},
\backslash
hat{i}_{j}
\backslash
right)
\backslash
right
\backslash
} 
\backslash
coloneqq
\backslash
operatorname*{argmaxlocal}_{x,y}
\backslash
operatorname*{argmax}_{i}
\backslash
operatorname{DoG}
\backslash
left(x,y,i
\backslash
right)$
\end_layout

\begin_layout Plain Layout


\backslash
Ensure{DOF $
\backslash
coloneqq 
\backslash
left| 
\backslash
left
\backslash
{ 
\backslash
left(
\backslash
hat{x}_{j},
\backslash
hat{y}_{j},
\backslash
hat{i}_{j}
\backslash
right)
\backslash
right
\backslash
} 
\backslash
right|$}
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% Thus our algorithm takes the form
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 
\backslash
begin{minted}[escapeinside=||,mathescape=true]{python}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% def create_embedded_kernel(sigma,height,width)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     # create (0, sigma) 2d gaussian kernel
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     # centered in array height x width
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% def get_local_maxima(dogs, sigma):
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% def detect_features(
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     image, n_bins, min_sigma, max_sigma
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% ):
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     img_h, img_w = image.shape
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     |$
\backslash
delta t$| = (max_sigma - min_sigma)/n_bins
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     sigmas = range(min_sigma, max_sigma+1, |$
\backslash
delta t$|)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     kernels = [
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%         create_embedded_kernel(s, img_h, img_w)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%         for s in sigmas
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     ]
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     filtered_imgs = |$
\backslash
mathcal{F}^{-1}
\backslash
{ 
\backslash
mathcal{F}
\backslash
{ 
\backslash
mathtt{image} 
\backslash
} * 
\backslash
mathcal{F}
\backslash
{ 
\backslash
mathtt{kernels} 
\backslash
}  
\backslash
}$| 
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%     dog = (filtered_imgs[:-1] -    filtered_imgs[1:]) * sigmas
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 
\backslash
end{minted}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Evaluation
\begin_inset CommandInset label
LatexCommand label
name "sec:Evaluation"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{subfigure}[b]
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

0.5
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textwidth
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand input
filename "nbin_vs_gpu.lyx"

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Median runtime as a function of number of feature scales at resolution 
\begin_inset Formula $=1024\times1024$
\end_inset

.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subfig:nbins"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{subfigure}
\end_layout

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset VSpace medskip
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{subfigure}[b]
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

0.5
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
textwidth
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand input
filename "res_vs_gpu.lyx"

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Median runtime as a function of section resolution with 16 feature scales.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subfig:res"

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{subfigure}
\end_layout

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Scaling experiments for runtime with respect to number of GPUs, resolution,
 and number of feature scales.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:evalplots"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Brains were prepared in the same manner and as previously described 
\begin_inset CommandInset citation
LatexCommand citet
literal "false"

\end_inset

.
 Briefly, an anesthetized animal was first transcardially perfused with
 10ml 0.1 M Sodium Cacodylate (cacodylate) buffer, pH 7.4 (Electron microscopy
 sciences (EMS) followed by 20 ml of fixative containing 2% paraformaldehyde
 (EMS), 2.5% glutaraldehyde (EMS) in 0.1 M Sodium Cacodylate (cacodylate)
 buffer, pH 7.4 (EMS).
 The brain was removed and placed in fixative for at least 24 hours at 4C.
 A series of 300 um vibratome sections were prepared and put into fixative
 for 24 hours at 4C.
 The primary visual cortex (V1) was identified using areal landmarks and
 reference atlases.
 A small piece (
\begin_inset space ~
\end_inset

2 x 2 mm) containing V1 was cut out and prepared for EM by staining sequentially
 with 2% osmium tetroxide (EMS) in cacodylate buffer, 2.5% potassium ferrocyanide
 (Sigma-Aldrich), thiocarbohydrazide, unbuffered 2% osmium tetroxide, 1%
 uranyl acetate, and 0.66% Aspartic acid buffered Lead (II) Nitrate with
 extensive rinses between each step with the exception of potassium ferrocyanide.
 The tissue was then dehydrated in ethanol and propylene oxide and infiltrated
 with 812 Epon resin (EMS, Mixture: 49% Embed 812, 28% DDSA, 21% NMA, and
 2.0% DMP 30).
 The resin-infiltrated tissue was cured at 60oC for 3 days.
 Using a commercial ultramicrotome (Powertome, RMC), the cured block was
 trimmed to a 
\begin_inset space ~
\end_inset

1.0mm x 1.5 mm rectangle and 
\begin_inset space ~
\end_inset

2,000, 40nm thick sections were collected on polyimide tape (Kapton) using
 an automated tape collecting device (ATUM, RMC) and assembled on silicon
 wafers as previously described (ref??).
 Images at different focal distances were acquired using backscattered electron
 detection with a Gemini 300 scanning electron microscope (Carl Zeiss),
 equipped with ATLAS software for automated imaging.
 Dwell times for all datasets were 1.0 microsecond.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Test platform
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace -2ex
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features tabularvalignment="top">
<column alignment="none" valignment="top" width="15line%">
<column alignment="none" valignment="top" width="75line%">
<row>
<cell alignment="none" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CPU 
\end_layout

\end_inset
</cell>
<cell alignment="none" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dual AMD Rome 7742 @ 2.25GHz 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="none" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GPU 
\end_layout

\end_inset
</cell>
<cell alignment="none" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8x NVIDIA A100-40GB 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="none" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
HD 
\end_layout

\end_inset
</cell>
<cell alignment="none" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4x 3.84 U.2 NVMe SSD 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="none" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RAM 
\end_layout

\end_inset
</cell>
<cell alignment="none" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1TB 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="none" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Software 
\end_layout

\end_inset
</cell>
<cell alignment="none" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CuPy-8.3.0, CUDA-11.0, NVIDIA-450.51.05 
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "tab:test"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We perform runtime experiments across a range of parameters of interest
 (section resolution, number of feature scales).
 Our test platform is a NVIDIA DGX A100 (see table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:test"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Experiments consist of computing the DOF of a sample section for a given
 configuration.
 All experiments are repeated 
\begin_inset Formula $k$
\end_inset

 times (with 
\begin_inset Formula $k=21$
\end_inset

) and all metrics reported are in fact median statistics
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We discard the first execution since it is an outlier due to various initializat
ions (e.g.
 pinning CUDA memory).
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
For a section resolution of 
\begin_inset Formula $1024\times1024$
\end_inset

 pixels we achieve approximately a 50Hz runtime in the single GPU configuration;
 this is near-real-time.
 We observe that, as expected, runtime grows linearly with the number of
 feature scales and quadratically with the resolution of the section; naturally,
 this is owing to the parallel architecture of the GPU.
 The principle defect of our technique is that it is highly dependent on
 the available RAM of the GPU it is deployed to.
 In practice, most GPUs available at the edge, i.e.
 proximal to microscopy instruments, will have insufficient ram to accommodate
 large section resolutions and wide feature scale ranges.
 In fact, even the 40GB of the DGX's A100 is exhausted at resolutions above
 
\begin_inset Formula $4096\times4096$
\end_inset

 for more than approximately 20 feature scales.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset

 
\begin_inset CommandInset include
LatexCommand input
preview true
filename "stacked_runtime.lyx"

\end_inset

 
\begin_inset Caption Standard

\begin_layout Plain Layout
Breakdown of runtime into the four major phases for two GPUs across feature
 scales at resolution 
\begin_inset Formula $=1024\times1024$
\end_inset

.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:stacked"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Therefore, we further investigate parallelizing MHFD across multiple GPUs.
 Our implementation parallelizes MHFD in a straightforward fashion: we partition
 the set of filters across the GPUs, perform the 
\begin_inset Quotes eld
\end_inset

lighter
\begin_inset Quotes erd
\end_inset

 FFT-IFFT pair on each constituent GPU, and then gather the results to the
 root GPU (arbitrarily chosen).
 That is to say we actually carry out 
\begin_inset Formula 
\[
\left\{ L\left(x,y,t_{i}\right)\mid i\in I_{m}\right\} =\big\{\mathcal{F}^{-1}\big\{\mathcal{F}\left\{ G\left(x,y,t_{i}\right)\right\} \cdot\mathcal{F}\left\{ I\left(x,y\right)\right\} \big\}\mid i\in I_{m}\big\}
\]

\end_inset

where for 
\begin_inset Formula $m=1,\dots,M$
\end_inset

 the set 
\begin_inset Formula $I_{m}$
\end_inset

 indexes the scales allocated to a node 
\begin_inset Formula $m$
\end_inset

.
 By partitioning the set of Gaussian filters 
\begin_inset Formula $\left\{ G\left(x,y,t_{i}\right)\right\} $
\end_inset

 across 
\begin_inset Formula $M$
\end_inset

 nodes, we effectively perform distributed filtering.
 We use CUDA-aware OpenMPI to implement the distribution.
 Note that for such multi-GPU configurations the range of feature scales
 was chosen to be a multiple of the number of GPUs (hence the proportionally
 increasing sparsity of data in figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subfig:nbins"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 We observe that, as one would expect, runtime is inversely proportional
 to number of GPUs (see figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subfig:res"
plural "false"
caps "false"
noprefix "false"

\end_inset

) but that for instances where a single GPU configuration is sufficient
 it is also optimal.
 More precise timing reveals that parallelization across multiple GPUs incurs
 high network copy costs during the gather phase (see figure 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig:stacked"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Note that this latency persists even after taking advantage of CUDA IPC
 
\begin_inset CommandInset citation
LatexCommand citep
key "6270863"
literal "false"

\end_inset

.
 In effect, this is a fairly obvious demonstration of Amdahl's law.
 Therefore, parallelization across multiple GPUs should be considered in
 instances where full resolution section images are necessary
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
For example, when feature scale range are very wide, with detection at the
 lower end of the scale being critical.
 In all other cases downsampling by bilinear interpolation in order to satisfy
 GPU RAM constraints yields a more than reasonable tradeoff between accuracy
 and latency.
\end_layout

\end_inset

.
\end_layout

\begin_layout Section
Discussion
\begin_inset CommandInset label
LatexCommand label
name "sec:Discussion"

\end_inset


\end_layout

\begin_layout Standard
As stated in the introduction our intent here was to study an OOF detection
 technique in order to augment existing microscopy instrumentation.
 Rather than focusing the microscope, as auto-focusing algorithms would,
 our algorithm operates downstream of image acquisition and reports out-of-focus
 events to the user.
 This enables the user to intervene and initiate reacquisition protocols
 (on the microscope) before unknowingly proceeding with collecting the next
 series of images or proceeding with downstream image processing and analysis.
 Our technique is effective and operates at near-real-time latencies.
 Thus, this human-in-the-loop remediation protocol already saves the user
 much wasted collection time and tedium in triaging defective collection
 runs.
 Note that MHFD could in fact be employed in an iterative mode in order
 that the DOF reported were used to adjust the focus of the microscope.
 This would require close integration with the existing software and actuation
 hardware of the microscope.
 
\end_layout

\begin_layout Standard
Though our technique is efficient for use with a single GPU for small to
 moderately sized image sections we emphasize that distribution across multiple
 nodes will inevitably be necessary for use with microscopy instrumentation
 in the near future.
 The current state of the art ZEISS MultiSEM 505/506 employs 91 parallel
 electron beams and images an entire 52 tile series in approximately 1.3s
 
\begin_inset CommandInset citation
LatexCommand citep
key "zeiss:multisem550"
literal "false"

\end_inset

; this is approximately 25ms per tile or exactly 50Hz (i.e.
 exactly the rate at which our technique operates).
 For maximal efficiency in the end-to-end automation of connectomics our
 solution (or refinements thereof) will need to be deployed and made available
 to researchers.
\end_layout

\begin_layout Section
Related work
\begin_inset CommandInset label
LatexCommand label
name "sec:related"

\end_inset

 
\end_layout

\begin_layout Standard
There is much work in developing and improving auto-focus algorithms and
 their applications to microscopy.
 Yeo et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "YEO1993629"
literal "false"

\end_inset

 was one of the first investigations of applying auto-focus to microscopy.
 They compare several criterion functions and conclude that the so-called
 Tenengrad criterion function is most accurate and most robust to noise.
 The crucial difference between their evaluation criteria and ours is they
 select for criterion functions that are suited for optical microscopy,
 i.e.
 criterion functions that are robust to staining/coloring (where as all
 of our samples are grayscale).
 Redondo et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "10.1117/1.JBO.17.3.036008"
literal "false"

\end_inset

 reviews sixteen criterion functions and their computational cost in the
 context of automated microscopy.
 Bian et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "https://doi.org/10.1002/jbio.202000227"
literal "false"

\end_inset

 address the same issues that motivate us in that they aim to support automated
 processes in the face of topographic variance in the samples (which lead
 to compare OOF rates).
 Their solutions distinguish themselves in that they employ active devices
 (such as low-coherence interferometry).
 Interestingly, seemingly contemporaneously with our project Luo et al.
 
\begin_inset CommandInset citation
LatexCommand citet
key "doi:10.1021/acsphotonics.0c01774"
literal "false"

\end_inset

 proposed a deep learning architecture that auto-focuses in a 
\begin_inset Quotes eld
\end_inset

single-shot
\begin_inset Quotes erd
\end_inset

 manner.
 Such a solution is quite appealing given the affinity with our own application
 of GPGPU to the problem and we intend to experiment with applying it to
 our data.
\end_layout

\begin_layout Acknowledgments
This work was supported by the U.S.
 Department of Energy, Office of Science, under contract DE-AC02-06CH11357.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 
\backslash
ryan{Marius LDRD}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "biblio"
options "ACM-Reference-Format"

\end_inset


\end_layout

\end_body
\end_document
